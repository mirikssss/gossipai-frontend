import os
import logging
import json
from typing import Dict, Any, Optional, List
import vertexai
from vertexai.preview.generative_models import GenerativeModel
from app.core.config import settings

# Set up logging
logger = logging.getLogger(__name__)

# Set Google Cloud credentials environment variable
if settings.GOOGLE_APPLICATION_CREDENTIALS:
    # Check if it's a JSON string or file path
    if settings.GOOGLE_APPLICATION_CREDENTIALS.startswith('{'):
        # It's a JSON string, create a temporary file
        import tempfile
        import json
        
        try:
            # Parse the JSON to validate it
            creds_data = json.loads(settings.GOOGLE_APPLICATION_CREDENTIALS)
            
            # Create a temporary file with the credentials
            temp_creds_file = tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json')
            json.dump(creds_data, temp_creds_file)
            temp_creds_file.close()
            
            # Set the environment variable to the temporary file path
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = temp_creds_file.name
            logger.info(f"Created temporary credentials file: {temp_creds_file.name}")
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in GOOGLE_APPLICATION_CREDENTIALS: {e}")
            # Try to use as file path
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = settings.GOOGLE_APPLICATION_CREDENTIALS
    else:
        # It's a file path
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = settings.GOOGLE_APPLICATION_CREDENTIALS
        logger.info(f"Set GOOGLE_APPLICATION_CREDENTIALS to file path: {settings.GOOGLE_APPLICATION_CREDENTIALS}")

# Initialize Vertex AI with error handling
vertex_ai_initialized = False
try:
    vertexai.init(project=settings.VERTEX_AI_PROJECT, location=settings.VERTEX_AI_LOCATION)
    logger.info(f"Vertex AI initialized with project: {settings.VERTEX_AI_PROJECT}, location: {settings.VERTEX_AI_LOCATION}")
    vertex_ai_initialized = True
except Exception as e:
    logger.error(f"Failed to initialize Vertex AI: {e}")
    vertex_ai_initialized = False

# In-memory storage for chat conversations (in production, use database)
chat_conversations = {}

class AIService:
    """Service for handling AI analysis with Google Vertex AI"""
    
    @staticmethod
    async def analyze_text(text: str, additional_prompt: Optional[str] = None, preset_id: Optional[str] = None, temperature: Optional[float] = None) -> Dict[str, Any]:
        """Analyze text using Google Vertex AI (Gemini)"""
        try:
            logger.info("Starting text analysis with Vertex AI")
            
            # Check if Vertex AI is initialized
            if not vertex_ai_initialized:
                logger.warning("Vertex AI not initialized, using mock analysis")
                return await AIService.mock_analysis_result(preset_id)
            
            # Check if credentials are set
            if not settings.GOOGLE_APPLICATION_CREDENTIALS:
                logger.warning("GOOGLE_APPLICATION_CREDENTIALS not set in settings")
                logger.info("Attempting to use default credentials...")
                # Try to continue without explicit credentials
            else:
                # Check if credentials file exists (only if it's a file path)
                creds_path = settings.GOOGLE_APPLICATION_CREDENTIALS
                if not creds_path.startswith('{') and not os.path.exists(creds_path):
                    logger.warning(f"Credentials file not found: {creds_path}")
                    logger.info("Attempting to use credentials from environment variable...")
                    # Try to continue without file - credentials might be set via environment
            
            logger.info("Initializing Gemini model")
            # Use the correct Gemini model for Vertex AI
            model = GenerativeModel("gemini-2.5-pro")
            
            # Apply preset-specific instructions if preset_id is provided
            preset_instructions = ""
            preset_specific_data = ""
            model_temperature = 0.7  # Default temperature
            
            if preset_id:
                from app.models.preset import get_preset_by_id
                preset = get_preset_by_id(preset_id)
                if preset:
                    logger.info(f"Using preset: {preset.name} with temperature {preset.temperature}")
                    preset_instructions = f"""
                    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–∞–∑–≥–æ–≤–æ—Ä —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ª–µ–¥—É—é—â–µ–º—É –ø—Ä–µ—Å–µ—Ç—É: "{preset.name}".
                    –¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è: {preset.target_audience}
                    
                    –°—Ç–∏–ª—å –æ—Ç—á–µ—Ç–∞:
                    {', '.join(preset.report_style)}
                    
                    –§–æ–∫—É—Å –∞–Ω–∞–ª–∏–∑–∞:
                    {', '.join(preset.focus_analysis)}
                    """
                    model_temperature = preset.temperature
                    
                    # Add preset-specific data generation instructions
                    if preset.id == "teen_navigator":
                        preset_specific_data = """
                        
                        –í–ê–ñ–ù–û: –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—å, –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ —ç—Ç–æ—Ç –¥–∏–∞–ª–æ–≥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–¥—Ä–æ—Å—Ç–∫–æ–≤–æ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏. 
                        –ò—â–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏: –≤–æ–∑—Ä–∞—Å—Ç —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ (–ø–æ–¥—Ä–æ—Å—Ç–∫–∏, —à–∫–æ–ª—å–Ω–∏–∫–∏), —à–∫–æ–ª—å–Ω–∞—è —Ç–µ–º–∞—Ç–∏–∫–∞, 
                        –≥—Ä—É–ø–ø–æ–≤–æ–µ –æ–±—â–µ–Ω–∏–µ, —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏, –ø–æ–¥—Ä–æ—Å—Ç–∫–æ–≤—ã–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã.
                        
                        –ï—Å–ª–∏ –¥–∏–∞–ª–æ–≥ –ù–ï –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø–æ–¥—Ä–æ—Å—Ç–∫–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞, —É—Å—Ç–∞–Ω–æ–≤–∏:
                        "preset_validation": {{
                            "is_valid": false,
                            "reason": "–î–∏–∞–ª–æ–≥ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ–¥—Ä–æ—Å—Ç–∫–æ–≤–æ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏"
                        }}
                        
                        –ï—Å–ª–∏ –¥–∏–∞–ª–æ–≥ –ø–æ–¥—Ö–æ–¥–∏—Ç, —É—Å—Ç–∞–Ω–æ–≤–∏:
                        "preset_validation": {{
                            "is_valid": true,
                            "reason": "–î–∏–∞–ª–æ–≥ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø–æ–¥—Ä–æ—Å—Ç–∫–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"
                        }}
                        
                        –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û –¥–ª—è –ø—Ä–µ—Å–µ—Ç–∞ "–ü–æ–¥—Ä–æ—Å—Ç–∫–æ–≤—ã–π –ù–∞–≤–∏–≥–∞—Ç–æ—Ä" –¥–æ–±–∞–≤—å —Å–ª–µ–¥—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ:
                        
                        "safety_check": {{
                            "bullying_indicators": ["–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä1", "–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä2", "–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä3"],
                            "safety_level": —á–∏—Å–ª–æ_–æ—Ç_0_–¥–æ_100,
                            "recommendations": ["—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è1", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è2", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è3"]
                        }},
                        "emotion_dictionary": {{
                            "hidden_emotions": [
                                {{
                                    "text": "—Ñ—Ä–∞–∑–∞ –∏–∑ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞",
                                    "explanation": "—á—Ç–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –æ–∑–Ω–∞—á–∞–µ—Ç —ç—Ç–∞ —Ñ—Ä–∞–∑–∞"
                                }}
                            ]
                        }},
                        "social_compass": {{
                            "group_dynamics": "–æ–ø–∏—Å–∞–Ω–∏–µ –≥—Ä—É–ø–ø–æ–≤–æ–π –¥–∏–Ω–∞–º–∏–∫–∏",
                            "inner_circles": ["–∫—Ä—É–≥1", "–∫—Ä—É–≥2", "–∫—Ä—É–≥3"],
                            "navigation_tips": ["—Å–æ–≤–µ—Ç1", "—Å–æ–≤–µ—Ç2", "—Å–æ–≤–µ—Ç3"]
                        }}
                        """
                    elif preset.id == "family_balance":
                        preset_specific_data = """
                        
                        –í–ê–ñ–ù–û: –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—å, –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ —ç—Ç–æ—Ç –¥–∏–∞–ª–æ–≥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–º–µ–π–Ω–æ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏. 
                        –ò—â–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏: —Å–µ–º–µ–π–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è (—Ä–æ–¥–∏—Ç–µ–ª–∏-–¥–µ—Ç–∏, —Å—É–ø—Ä—É–≥–∏, —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫–∏), 
                        –¥–æ–º–∞—à–Ω–∏–µ –¥–µ–ª–∞, —Å–µ–º–µ–π–Ω—ã–µ –ø–ª–∞–Ω—ã, –≤–æ—Å–ø–∏—Ç–∞–Ω–∏–µ, —Å–µ–º–µ–π–Ω—ã–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã.
                        
                        –ï—Å–ª–∏ –¥–∏–∞–ª–æ–≥ –ù–ï –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å–µ–º–µ–π–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞, —É—Å—Ç–∞–Ω–æ–≤–∏:
                        "preset_validation": {{
                            "is_valid": false,
                            "reason": "–î–∏–∞–ª–æ–≥ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–µ–º–µ–π–Ω–æ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏"
                        }}
                        
                        –ï—Å–ª–∏ –¥–∏–∞–ª–æ–≥ –ø–æ–¥—Ö–æ–¥–∏—Ç, —É—Å—Ç–∞–Ω–æ–≤–∏:
                        "preset_validation": {{
                            "is_valid": true,
                            "reason": "–î–∏–∞–ª–æ–≥ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å–µ–º–µ–π–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"
                        }}
                        
                        –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û –¥–ª—è –ø—Ä–µ—Å–µ—Ç–∞ "–°–µ–º–µ–π–Ω—ã–π –ë–∞–ª–∞–Ω—Å" –¥–æ–±–∞–≤—å —Å–ª–µ–¥—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ:
                        
                        "communication_cycles": {{
                            "patterns": ["–ø–∞—Ç—Ç–µ—Ä–Ω1", "–ø–∞—Ç—Ç–µ—Ä–Ω2", "–ø–∞—Ç—Ç–µ—Ä–Ω3"],
                            "trigger_points": ["—Ç—Ä–∏–≥–≥–µ—Ä1", "—Ç—Ä–∏–≥–≥–µ—Ä2", "—Ç—Ä–∏–≥–≥–µ—Ä3"],
                            "interruption_techniques": ["—Ç–µ—Ö–Ω–∏–∫–∞1", "—Ç–µ—Ö–Ω–∏–∫–∞2", "—Ç–µ—Ö–Ω–∏–∫–∞3"]
                        }},
                        "needs_map": {{
                            "expressed_needs": ["–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å1", "–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å2"],
                            "unexpressed_needs": ["—Å–∫—Ä—ã—Ç–∞—è_–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å1", "—Å–∫—Ä—ã—Ç–∞—è_–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å2"],
                            "overlap_areas": ["–∑–æ–Ω–∞_–ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è1", "–∑–æ–Ω–∞_–ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è2"]
                        }},
                        "family_roles": {{
                            "role_distribution": ["—Ä–æ–ª—å1", "—Ä–æ–ª—å2", "—Ä–æ–ª—å3"],
                            "responsibility_balance": —á–∏—Å–ª–æ_–æ—Ç_0_–¥–æ_100,
                            "recommendations": ["—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è1", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è2", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è3"]
                        }}
                        –ü–†–ê–í–ò–õ–ê –û–§–û–†–ú–õ–ï–ù–ò–Ø:
                        1. –ö–û–õ–ò–ß–ï–°–¢–í–û –°–õ–û–í –ö–ê–ñ–î–û–ì–û –¢–†–ò–ì–ï–†–ê –ù–ï –î–û–õ–ñ–ù–´ –ü–†–ï–í–´–®–ê–¢–¨ 4-5 –°–õ–û–í
                        2. –í–°–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–û–õ–ñ–ù–´ –ë–´–¢–¨ –ù–ï –î–õ–ò–ù–ù–´–ú–ò –ò –ü–†–ê–ö–¢–ò–ß–ù–´–ú–ò
                        """
                    elif preset.id == "strategic_hr":
                        preset_specific_data = """
                        
                        –í–ê–ñ–ù–û: –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—å, –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ —ç—Ç–æ—Ç –¥–∏–∞–ª–æ–≥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–µ–ª–æ–≤–æ–π/—Ä–∞–±–æ—á–µ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏. 
                        –ò—â–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏: —Ä–∞–±–æ—á–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è, –ø—Ä–æ–µ–∫—Ç—ã, –∑–∞–¥–∞—á–∏, —Å–æ–≤–µ—â–∞–Ω–∏—è, 
                        –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –æ–±—Å—É–∂–¥–µ–Ω–∏—è, –∫–æ–º–∞–Ω–¥–Ω–∞—è —Ä–∞–±–æ—Ç–∞, –¥–µ–ª–æ–≤—ã–µ —Ä–µ—à–µ–Ω–∏—è.
                        
                        –ï—Å–ª–∏ –¥–∏–∞–ª–æ–≥ –ù–ï –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è HR –∞–Ω–∞–ª–∏–∑–∞, —É—Å—Ç–∞–Ω–æ–≤–∏:
                        "preset_validation": {{
                            "is_valid": false,
                            "reason": "–î–∏–∞–ª–æ–≥ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–µ–ª–æ–≤–æ–π/—Ä–∞–±–æ—á–µ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏"
                        }}
                        
                        –ï—Å–ª–∏ –¥–∏–∞–ª–æ–≥ –ø–æ–¥—Ö–æ–¥–∏—Ç, —É—Å—Ç–∞–Ω–æ–≤–∏:
                        "preset_validation": {{
                            "is_valid": true,
                            "reason": "–î–∏–∞–ª–æ–≥ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è HR –∞–Ω–∞–ª–∏–∑–∞"
                        }}
                        
                        –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û –¥–ª—è –ø—Ä–µ—Å–µ—Ç–∞ "–°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π HR" –¥–æ–±–∞–≤—å —Å–ª–µ–¥—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ:
                        
                        "team_analytics": {{
                            "communication_metrics": {{
                                "participation_rate": —á–∏—Å–ª–æ_–æ—Ç_0_–¥–æ_100,
                                "response_time": "—Å—Ä–µ–¥–Ω–µ–µ_–≤—Ä–µ–º—è_–æ—Ç–≤–µ—Ç–∞",
                                "engagement_score": —á–∏—Å–ª–æ_–æ—Ç_0_–¥–æ_100
                            }},
                            "decision_efficiency": —á–∏—Å–ª–æ_–æ—Ç_0_–¥–æ_100,
                            "goal_achievement": —á–∏—Å–ª–æ_–æ—Ç_0_–¥–æ_100
                        }},
                        "psychological_safety": {{
                            "safety_level": —á–∏—Å–ª–æ_–æ—Ç_0_–¥–æ_100,
                            "trust_indicators": ["–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä1", "–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä2", "–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä3"],
                            "openness_score": —á–∏—Å–ª–æ_–æ—Ç_0_–¥–æ_100
                        }},
                        "professional_growth": {{
                            "skill_analysis": [
                                {{
                                    "skill": "–Ω–∞–≤—ã–∫",
                                    "current_level": —á–∏—Å–ª–æ_–æ—Ç_1_–¥–æ_5,
                                    "development_area": "–æ–±–ª–∞—Å—Ç—å_—Ä–∞–∑–≤–∏—Ç–∏—è"
                                }}
                            ],
                            "growth_recommendations": ["—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è1", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è2", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è3"]
                        }}
                        """
            
            # Override with provided temperature if specified
            if temperature is not None:
                model_temperature = temperature
            
            # Create the prompt for analysis
            prompt = f"""
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—â–µ–Ω–∏—è. 
            –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

            –†–∞–∑–≥–æ–≤–æ—Ä:
            {text}

            {preset_instructions}
            
            –í–ê–ñ–ù–û: –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –∫–æ—Ä–æ—Ç–∫–∏–π –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∞–ª–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –≤—Å–µ —Ä–∞–≤–Ω–æ –ø—Ä–æ–≤–µ–¥–∏ –∞–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
            –î–∞–∂–µ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
            
            {f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏: {additional_prompt}" if additional_prompt else ""}

            –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∞–Ω–∞–ª–∏–∑ –≤ —Å–ª–µ–¥—É—é—â–µ–º JSON —Ñ–æ—Ä–º–∞—Ç–µ (give answers in russian):

            {{
                "summary": {{
                    "overview": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞",
                    "participants": –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—É—á–∞—Å—Ç–Ω–∏–∫–æ–≤,
                    "messageCount": –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Å–æ–æ–±—â–µ–Ω–∏–π,
                    "duration": "–ø—Ä–∏–º–µ—Ä–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
                    "mainTopics": ["—Ç–µ–º–∞1", "—Ç–µ–º–∞2", "—Ç–µ–º–∞3"]
                }},
                "emotionTimeline": {{
                    "emotions": [
                        {{
                            "time": "–≤—Ä–µ–º—è",
                            "emotion": "—ç–º–æ—Ü–∏—è —Å —ç–º–æ–¥–∂–∏",
                            "intensity": –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å_–æ—Ç_0_–¥–æ_100,
                            "color": "hex_—Ü–≤–µ—Ç"
                        }}
                    ],
                    "dominantEmotion": "–¥–æ–º–∏–Ω–∏—Ä—É—é—â–∞—è —ç–º–æ—Ü–∏—è —Å —ç–º–æ–¥–∂–∏",
                    "emotionalShifts": –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö_–ø–µ—Ä–µ—Ö–æ–¥–æ–≤
                }},
                "aiJudgeScore": {{
                    "overallScore": –æ–±—â–∏–π_–±–∞–ª–ª_–æ—Ç_0_–¥–æ_100,
                    "breakdown": {{
                        "clarity": –±–∞–ª–ª_—è—Å–Ω–æ—Å—Ç–∏_–æ—Ç_0_–¥–æ_100,
                        "empathy": –±–∞–ª–ª_—ç–º–ø–∞—Ç–∏–∏_–æ—Ç_0_–¥–æ_100,
                        "professionalism": –±–∞–ª–ª_–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–∏–∑–º–∞_–æ—Ç_0_–¥–æ_100,
                        "resolution": –±–∞–ª–ª_—Ä–µ—à–µ–Ω–∏—è_–æ—Ç_0_–¥–æ_100
                    }},
                    "verdict": "–ö–†–ê–¢–ö–ò–ô –í–ï–†–î–ò–ö–¢ –ò–ó 4-5 –°–õ–û–í –ú–ê–ö–°–ò–ú–£–ú",
                    "recommendation": "–ø–æ–¥—Ä–æ–±–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è"
                }},
                "subtleties": [
                    {{
                        "type": "—Ç–∏–ø —Ç–æ–Ω–∫–æ—Å—Ç–∏",
                        "message": "–æ–ø–∏—Å–∞–Ω–∏–µ",
                        "confidence": —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å_–æ—Ç_0_–¥–æ_100,
                        "context": "–∫–æ–Ω—Ç–µ–∫—Å—Ç"
                    }}
                ]{preset_specific_data}
            }}

            –í–ê–ñ–ù–û:
            1. –í–µ—Ä–¥–∏–∫—Ç (verdict) –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ö–†–ê–¢–ö–ò–ú - –º–∞–∫—Å–∏–º—É–º 4-5 —Å–ª–æ–≤
            2. –ö –∫–∞–∂–¥–æ–π —ç–º–æ—Ü–∏–∏ –≤ emotionTimeline.emotions –¥–æ–±–∞–≤–ª—è–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π —ç–º–æ–¥–∂–∏
            3. –ö dominantEmotion —Ç–æ–∂–µ –¥–æ–±–∞–≤–ª—è–π —ç–º–æ–¥–∂–∏
            4. –í—Å–µ –æ—Ç–≤–µ—Ç—ã —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
            """
            
            # Add additional prompt if provided
            if additional_prompt:
                prompt += f"\n\nAdditional analysis instructions: {additional_prompt}"
            
            logger.info(f"Generating content with Gemini using temperature {model_temperature}")
            logger.info(f"Prompt length: {len(prompt)} characters")
            logger.info(f"Text to analyze: {text[:100]}...")
            
            # Generate response from Gemini with specified temperature
            response = model.generate_content(prompt, generation_config={"temperature": model_temperature})
            
            # Parse the response to extract the JSON
            result = response.text
            logger.info(f"Successfully generated analysis, response length: {len(result)} characters")
            logger.info(f"Response preview: {result[:200]}...")
            
            # Try to parse JSON from the response
            try:
                # Extract JSON from the response (it might be wrapped in markdown)
                if "```json" in result:
                    json_start = result.find("```json") + 7
                    json_end = result.find("```", json_start)
                    json_str = result[json_start:json_end].strip()
                elif "```" in result:
                    # Handle other markdown code blocks
                    json_start = result.find("```") + 3
                    json_end = result.find("```", json_start)
                    json_str = result[json_start:json_end].strip()
                else:
                    json_str = result.strip()
                
                logger.info(f"Attempting to parse JSON: {json_str[:200]}...")
                parsed_result = json.loads(json_str)
                
                # Add preset-specific data to the result if preset is provided
                if preset_id:
                    from app.models.preset import get_preset_by_id
                    preset = get_preset_by_id(preset_id)
                    if preset and hasattr(preset, 'custom_cards') and preset.custom_cards:
                        # Add information about custom cards that should be shown for this preset
                        parsed_result["preset"] = {
                            "id": preset.id,
                            "name": preset.name,
                            "custom_cards": [card.dict() for card in preset.custom_cards]
                        }
                
                return {
                    "success": True,
                    "result": parsed_result
                }
            except json.JSONDecodeError as e:
                logger.warning(f"Failed to parse JSON from response: {e}")
                logger.warning(f"Raw response: {result}")
                # Try to create a basic analysis from the raw text
                try:
                    # Create a basic analysis structure from the raw response
                    basic_analysis = {
                        "summary": {
                            "overview": "–ê–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞",
                            "participants": 1,
                            "messageCount": len(text.split()),
                            "duration": "–ö—Ä–∞—Ç–∫–∏–π",
                            "mainTopics": ["–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞"]
                        },
                        "emotionTimeline": {
                            "emotions": [
                                {
                                    "time": "00:00",
                                    "emotion": "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π",
                                    "intensity": 50,
                                    "color": "#6b7280"
                                }
                            ],
                            "dominantEmotion": "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π",
                            "emotionalShifts": 1
                        },
                        "aiJudgeScore": {
                            "overallScore": 70,
                            "breakdown": {
                                "clarity": 75,
                                "empathy": 70,
                                "professionalism": 65,
                                "resolution": 70
                            },
                            "verdict": "–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω",
                            "recommendation": "–¢–µ–∫—Å—Ç —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"
                        },
                        "subtleties": [
                            {
                                "type": "–û–±—Ä–∞–±–æ—Ç–∫–∞",
                                "message": "–¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω",
                                "confidence": 80,
                                "context": "OCR –∏ AI –∞–Ω–∞–ª–∏–∑"
                            }
                        ]
                    }
                    return {
                        "success": True,
                        "result": basic_analysis
                    }
                except Exception as fallback_error:
                    logger.error(f"Fallback analysis also failed: {fallback_error}")
                    return {
                        "success": True,
                        "result": result
                    }
            
        except Exception as e:
            logger.error(f"Error in text analysis: {str(e)}")
            logger.error(f"Text length: {len(text)} characters")
            logger.error(f"Text preview: {text[:200]}...")
            # Fallback to mock analysis
            logger.warning("Falling back to mock analysis due to error")
            return await AIService.mock_analysis_result(preset_id)
    
    @staticmethod
    async def chat_with_ai(message: str, conversation_id: Optional[str] = None) -> Dict[str, Any]:
        """Chat with AI about the analyzed conversation"""
        try:
            logger.info("Starting AI chat")
            
            # Check if Vertex AI is initialized
            if not vertex_ai_initialized:
                logger.warning("Vertex AI not initialized, using mock chat")
                return await AIService.mock_chat_response()
            
            # Get conversation history
            conversation_history = chat_conversations.get(conversation_id, [])
            
            # Keep only last 10 messages
            if len(conversation_history) > 10:
                conversation_history = conversation_history[-10:]
            
            # Create context from conversation history
            context = ""
            if conversation_history:
                context = "–ü—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è:\n" + "\n".join([
                    f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {msg['user']}\nAI: {msg['ai']}" 
                    for msg in conversation_history
                ])
            
            # Create prompt for chat
            chat_prompt = f"""
            –¢—ã - –ò–ò-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
            
            –ö–æ–Ω—Ç–µ–∫—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:
            {context}
            
            –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {message}
            
            –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∞–Ω–∞–ª–∏–∑–∞. 
            –ú–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç–º–æ–¥–∂–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è —ç–º–æ—Ü–∏–π.
            """
            
            logger.info("Generating chat response with Gemini")
            model = GenerativeModel("gemini-2.5-pro")
            response = model.generate_content(chat_prompt)
            
            ai_response = response.text.strip()
            
            # Store the conversation
            if conversation_id:
                if conversation_id not in chat_conversations:
                    chat_conversations[conversation_id] = []
                
                chat_conversations[conversation_id].append({
                    "user": message,
                    "ai": ai_response
                })
                
                # Keep only last 10 messages
                if len(chat_conversations[conversation_id]) > 10:
                    chat_conversations[conversation_id] = chat_conversations[conversation_id][-10:]
            
            return {
                "success": True,
                "response": ai_response,
                "conversation_id": conversation_id
            }
            
        except Exception as e:
            logger.error(f"Error in AI chat: {str(e)}")
            return await AIService.mock_chat_response()
    
    @staticmethod
    async def get_suggested_responses(conversation_text: str, context: Optional[str] = None) -> Dict[str, Any]:
        """Get suggested responses based on conversation analysis"""
        try:
            logger.info("Getting suggested responses")
            
            # Check if Vertex AI is initialized
            if not vertex_ai_initialized:
                logger.warning("Vertex AI not initialized, using mock suggestions")
                return await AIService.mock_suggested_responses()
            
            # Create prompt for suggested responses
            prompt = f"""
            –ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –ø—Ä–µ–¥–ª–æ–∂–∏ 3 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ—Ä–∞–∑—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±—â–µ–Ω–∏—è.
            
            –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:
            {conversation_text}
            
            {f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {context}" if context else ""}
            
            –ü—Ä–µ–¥–ª–æ–∂–∏ 3 —Ñ—Ä–∞–∑—ã –≤ —Å–ª–µ–¥—É—é—â–µ–º JSON —Ñ–æ—Ä–º–∞—Ç–µ:
            {{
                "suggestions": [
                    {{
                        "text": "–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —Ñ—Ä–∞–∑–∞ —Å —ç–º–æ–¥–∂–∏",
                        "reason": "–∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ—á–µ–º—É —ç—Ç–∞ —Ñ—Ä–∞–∑–∞ –ø–æ–¥—Ö–æ–¥–∏—Ç"
                    }},
                    {{
                        "text": "–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —Ñ—Ä–∞–∑–∞ —Å —ç–º–æ–¥–∂–∏", 
                        "reason": "–∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ—á–µ–º—É —ç—Ç–∞ —Ñ—Ä–∞–∑–∞ –ø–æ–¥—Ö–æ–¥–∏—Ç"
                    }},
                    {{
                        "text": "–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —Ñ—Ä–∞–∑–∞ —Å —ç–º–æ–¥–∂–∏",
                        "reason": "–∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ—á–µ–º—É —ç—Ç–∞ —Ñ—Ä–∞–∑–∞ –ø–æ–¥—Ö–æ–¥–∏—Ç"
                    }}
                ]
            }}
            
            –í–ê–ñ–ù–û:
            1. –í—Å–µ –æ—Ç–≤–µ—Ç—ã —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
            2. –î–æ–±–∞–≤–ª—è–π –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —ç–º–æ–¥–∂–∏ –∫ —Ñ—Ä–∞–∑–∞–º
            3. –§—Ä–∞–∑—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –∏ –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–º–∏
            4. –û–±—ä—è—Å–Ω–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º–∏
            """
            
            logger.info("Generating suggested responses with Gemini")
            model = GenerativeModel("gemini-2.5-pro")
            response = model.generate_content(prompt)
            
            result = response.text
            
            # Try to parse JSON from the response
            try:
                if "```json" in result:
                    json_start = result.find("```json") + 7
                    json_end = result.find("```", json_start)
                    json_str = result[json_start:json_end].strip()
                else:
                    json_str = result.strip()
                
                parsed_result = json.loads(json_str)
                return {
                    "success": True,
                    "suggestions": parsed_result.get("suggestions", [])
                }
            except json.JSONDecodeError as e:
                logger.warning(f"Failed to parse JSON from response: {e}")
                # Return mock suggestions if parsing fails
                return await AIService.mock_suggested_responses()
            
        except Exception as e:
            logger.error(f"Error in getting suggested responses: {str(e)}")
            return await AIService.mock_suggested_responses()
    
    @staticmethod
    async def mock_analysis_result(preset_id: Optional[str] = None) -> Dict[str, Any]:
        """Mock analysis result for testing"""
        result = {
            "result": {
                "summary": {
                    "overview": "–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥ –º–µ–∂–¥—É –∫–ª–∏–µ–Ω—Ç–æ–º –∏ –ø—Ä–æ–¥–∞–≤—Ü–æ–º –æ –ø–æ–∫—É–ø–∫–µ —Ç–æ–≤–∞—Ä–∞",
                    "participants": 2,
                    "messageCount": 15,
                    "duration": "15 –º–∏–Ω—É—Ç",
                    "mainTopics": ["–ø–æ–∫—É–ø–∫–∞", "–¥–æ—Å—Ç–∞–≤–∫–∞", "–æ–ø–ª–∞—Ç–∞"]
                },
                "emotionTimeline": {
                    "emotions": [
                        {"time": "10:00", "emotion": "–õ—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ ü§î", "intensity": 70, "color": "#FFD700"},
                        {"time": "10:05", "emotion": "–ò–Ω—Ç–µ—Ä–µ—Å üòä", "intensity": 85, "color": "#32CD32"},
                        {"time": "10:10", "emotion": "–°–æ–≥–ª–∞—Å–∏–µ üëç", "intensity": 90, "color": "#00CED1"}
                    ],
                    "dominantEmotion": "–ü–æ–∑–∏—Ç–∏–≤ üòä",
                    "emotionalShifts": 2
                },
                "aiJudgeScore": {
                    "overallScore": 85,
                    "breakdown": {
                        "clarity": 90,
                        "empathy": 85,
                        "professionalism": 80,
                        "resolution": 85
                    },
                    "verdict": "–û—Ç–ª–∏—á–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ",
                    "recommendation": "–û–±–∞ —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø—Ä–æ—è–≤–∏–ª–∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–∏–∑–º –∏ —ç–º–ø–∞—Ç–∏—é. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Ç–∞–∫–æ–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è."
                },
                "subtleties": [
                    {
                        "type": "–ü—Ä–æ–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å",
                        "message": "–ü—Ä–æ–¥–∞–≤–µ—Ü –∑–∞—Ä–∞–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–∏–ª –≤–∞—Ä–∏–∞–Ω—Ç—ã –¥–æ—Å—Ç–∞–≤–∫–∏",
                        "confidence": 95,
                        "context": "–£–ø–æ–º–∏–Ω–∞–Ω–∏–µ –æ —Ä–∞–∑–Ω—ã—Ö —Å–ø–æ—Å–æ–±–∞—Ö –¥–æ—Å—Ç–∞–≤–∫–∏"
                    }
                ]
            }
        }
        
        # Add preset-specific data if preset_id is provided
        if preset_id:
            from app.models.preset import get_preset_by_id
            preset = get_preset_by_id(preset_id)
            if preset and hasattr(preset, 'custom_cards') and preset.custom_cards:
                # Add mock data for preset-specific custom cards
                result["result"]["preset"] = {
                    "id": preset.id,
                    "name": preset.name,
                    "custom_cards": [card.dict() for card in preset.custom_cards]
                }
                
                # Add mock data for teen navigator preset
                if preset.id == "teen_navigator":
                    # Mock validation - this would normally be determined by LLM
                    result["result"]["preset_validation"] = {
                        "is_valid": False,
                        "reason": "–î–∏–∞–ª–æ–≥ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ–¥—Ä–æ—Å—Ç–∫–æ–≤–æ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏"
                    }
                    result["result"]["safety_check"] = {
                        "bullying_indicators": ["–ù–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –±—É–ª–ª–∏–Ω–≥–∞", "–ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è —É–≤–∞–∂–∏—Ç–µ–ª—å–Ω–∞—è"],
                        "safety_level": 90,
                        "recommendations": ["–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –æ—Ç–∫—Ä—ã—Ç—ã–π –¥–∏–∞–ª–æ–≥", "–û–±—Å—É–∂–¥–∞–π—Ç–µ –≥—Ä–∞–Ω–∏—Ü—ã"]
                    }
                    result["result"]["emotion_dictionary"] = {
                        "hidden_emotions": [
                            {"text": "–í–æ–∑–º–æ–∂–Ω–æ –≤–æ–ª–Ω–µ–Ω–∏–µ", "explanation": "–ß–∞—Å—Ç—ã–µ —É—Ç–æ—á–Ω–µ–Ω–∏—è –º–æ–≥—É—Ç –≥–æ–≤–æ—Ä–∏—Ç—å –æ –±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–µ"},
                            {"text": "–°–∫—Ä—ã—Ç—ã–π —ç–Ω—Ç—É–∑–∏–∞–∑–º", "explanation": "–ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –≤–æ–ø—Ä–æ—Å—ã –æ –¥–µ—Ç–∞–ª—è—Ö –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å"}
                        ]
                    }
                    result["result"]["social_compass"] = {
                        "group_dynamics": "–†–∞–≤–Ω–æ–µ —É—á–∞—Å—Ç–∏–µ –æ–±–µ–∏—Ö —Å—Ç–æ—Ä–æ–Ω",
                        "inner_circles": ["–ü—Ä–æ–¥–∞–≤–µ—Ü –∏ –∫–ª–∏–µ–Ω—Ç –æ–±—Ä–∞–∑—É—é—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∫—Ä—É–≥"],
                        "navigation_tips": ["–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ –±–∞–ª–∞–Ω—Å –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤", "–£—Ç–æ—á–Ω—è–π—Ç–µ –¥–µ—Ç–∞–ª–∏ –±–µ–∑ –¥–∞–≤–ª–µ–Ω–∏—è"]
                    }
                
                # Add mock data for family balance preset
                elif preset.id == "family_balance":
                    # Mock validation - this would normally be determined by LLM
                    result["result"]["preset_validation"] = {
                        "is_valid": False,
                        "reason": "–î–∏–∞–ª–æ–≥ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–µ–º–µ–π–Ω–æ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏"
                    }
                    result["result"]["communication_cycles"] = {
                        "patterns": ["–í–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç-—É—Ç–æ—á–Ω–µ–Ω–∏–µ", "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ-—Å–æ–≥–ª–∞—Å–∏–µ"],
                        "trigger_points": ["–û–±—Å—É–∂–¥–µ–Ω–∏–µ —Ü–µ–Ω—ã –º–æ–∂–µ—Ç –≤—ã–∑—ã–≤–∞—Ç—å –Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ"],
                        "interruption_techniques": ["–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞—É–∑", "–ü–µ—Ä–µ—Ö–æ–¥ –∫ –æ–±—Å—É–∂–¥–µ–Ω–∏—é –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤"]
                    }
                    result["result"]["needs_map"] = {
                        "expressed_needs": ["–ö–ª–∏–µ–Ω—Ç: –Ω—É–∂–Ω–∞ –ø–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è", "–ü—Ä–æ–¥–∞–≤–µ—Ü: –Ω—É–∂–Ω–æ –∑–∞–≤–µ—Ä—à–∏—Ç—å –ø—Ä–æ–¥–∞–∂—É"],
                        "unexpressed_needs": ["–ö–ª–∏–µ–Ω—Ç: —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ä–µ—à–µ–Ω–∏–∏", "–ü—Ä–æ–¥–∞–≤–µ—Ü: –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å –∫–ª–∏–µ–Ω—Ç–æ–º"],
                        "overlap_areas": ["–í–∑–∞–∏–º–Ω–∞—è –≤—ã–≥–æ–¥–∞ –æ—Ç —Å–¥–µ–ª–∫–∏", "–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ"]
                    }
                    result["result"]["family_roles"] = {
                        "role_distribution": ["–ü—Ä–æ–¥–∞–≤–µ—Ü –≤—ã—Å—Ç—É–ø–∞–µ—Ç –∫–∞–∫ —ç–∫—Å–ø–µ—Ä—Ç", "–ö–ª–∏–µ–Ω—Ç –≤ —Ä–æ–ª–∏ –ø—Ä–∏–Ω–∏–º–∞—é—â–µ–≥–æ —Ä–µ—à–µ–Ω–∏—è"],
                        "responsibility_balance": 70,
                        "recommendations": ["–°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –±–∞–ª–∞–Ω—Å —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ—Å—Ç–∏ –∏ —É–≤–∞–∂–µ–Ω–∏—è –∫ –≤—ã–±–æ—Ä—É", "–ü–æ–¥—á–µ—Ä–∫–∏–≤–∞–π—Ç–µ —Å–æ–≤–º–µ—Å—Ç–Ω—É—é –≤—ã–≥–æ–¥—É"]
                    }
                
                # Add mock data for strategic HR preset
                elif preset.id == "strategic_hr":
                    # Mock validation - this would normally be determined by LLM
                    result["result"]["preset_validation"] = {
                        "is_valid": False,
                        "reason": "–î–∏–∞–ª–æ–≥ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–µ–ª–æ–≤–æ–π/—Ä–∞–±–æ—á–µ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏"
                    }
                    result["result"]["team_analytics"] = {
                        "communication_metrics": {
                            "participation_rate": 85,
                            "response_time": "2-3 –º–∏–Ω—É—Ç—ã",
                            "engagement_score": 80
                        },
                        "decision_efficiency": 75,
                        "goal_achievement": 90
                    }
                    result["result"]["psychological_safety"] = {
                        "safety_level": 80,
                        "trust_indicators": ["–û—Ç–∫—Ä—ã—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã", "–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å", "–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –¥–∏–∞–ª–æ–≥—É"],
                        "openness_score": 85
                    }
                    result["result"]["professional_growth"] = {
                        "skill_analysis": [
                            {
                                "skill": "–ê–∫—Ç–∏–≤–Ω–æ–µ —Å–ª—É—à–∞–Ω–∏–µ",
                                "current_level": 4,
                                "development_area": "–¢–µ—Ö–Ω–∏–∫–∏ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏—è"
                            },
                            {
                                "skill": "–≠–º–ø–∞—Ç–∏—è",
                                "current_level": 5,
                                "development_area": "–£–∂–µ –Ω–∞ –≤—ã—Å–æ–∫–æ–º —É—Ä–æ–≤–Ω–µ"
                            }
                        ],
                        "growth_recommendations": ["–¢—Ä–µ–Ω–∏–Ω–≥ –ø–æ –∞–∫—Ç–∏–≤–Ω–æ–º—É —Å–ª—É—à–∞–Ω–∏—é", "–ü—Ä–∞–∫—Ç–∏–∫–∞ —ç–º–ø–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±—â–µ–Ω–∏—è", "–†–∞–±–æ—Ç–∞ —Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é"]
                    }
        
        return result
    
    @staticmethod
    async def mock_chat_response() -> Dict[str, Any]:
        """Mock chat response for testing"""
        return {
            "success": True,
            "response": "–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å! üòä –û—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ, —è –≤–∏–∂—É, —á—Ç–æ –æ–±—â–µ–Ω–∏–µ –±—ã–ª–æ –æ—á–µ–Ω—å –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–º. –û–±–∞ —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø—Ä–æ—è–≤–∏–ª–∏ —ç–º–ø–∞—Ç–∏—é –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–∏–∑–º. –†–µ–∫–æ–º–µ–Ω–¥—É—é –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Ç–∞–∫–æ–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è! üëç"
        }

    @staticmethod
    async def mock_suggested_responses() -> Dict[str, Any]:
        """Mock suggested responses for testing"""
        return {
            "success": True,
            "suggestions": [
                {
                    "text": "–ü–æ–Ω–∏–º–∞—é —Ç–≤–æ—é —Ç–æ—á–∫—É –∑—Ä–µ–Ω–∏—è! ü§ù",
                    "reason": "–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —ç–º–ø–∞—Ç–∏—é –∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –¥–∏–∞–ª–æ–≥—É"
                },
                {
                    "text": "–†–∞—Å—Å–∫–∞–∂–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ, –º–Ω–µ –≤–∞–∂–Ω–æ —É—Å–ª—ã—à–∞—Ç—å —Ç–≤–æ–µ –º–Ω–µ–Ω–∏–µ üí¨",
                    "reason": "–ü–æ–æ—â—Ä—è–µ—Ç –æ—Ç–∫—Ä—ã—Ç—É—é –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—é"
                },
                {
                    "text": "–î–∞–≤–∞–π —Å–¥–µ–ª–∞–µ–º –ø–∞—É–∑—É –∏ –≤–µ—Ä–Ω–µ–º—Å—è –ø–æ–∑–∂–µ ‚è∞",
                    "reason": "–ü–æ–º–æ–≥–∞–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å —ç—Å–∫–∞–ª–∞—Ü–∏–∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞"
                }
            ]
        }
